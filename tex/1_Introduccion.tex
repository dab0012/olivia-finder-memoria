\capitulo{1}{Introducción}


Uno de los principios más importantes de la ingeniería del software es aprovechar al máximo los componentes existentes \cite{sametinger1997software}.
El empleo de librerías externas para disminuir los tiempos de desarrollo y costes es prácticamente universal,
en todos los lenguajes y tipos de proyecto software. En una encuesta realizada por Sonartype en 2014, más de once mil arquitectos y
desarrolladores revelaron que el 90\% del código de una aplicación típica en la actualidad está compuesto por componentes externos.
Además, más del 80\% de los proyectos utilizan repositorios centralizados de componentes.
Estos repositorios están configurados por defecto en las herramientas que usamos para instalar y administrar los paquetes de cada lenguaje.
Son como almacenes gigantes que contienen componentes los cuales aportan alguna utilidad.
Algunos ejemplos famosos son PyPI (Python Package Index), npm (Node Package Manager) para JavaScript (Node.js),
CRAN y Bioconductor para R, CPAN (Comprehensive Perl Archive Network) y Maven Central para Java.


El problema reside en que hay veces que utilizar componentes externos tiene sus riesgos. Esos riesgos pueden ser difíciles de 
notar para los desarrolladores, ya que solo importan explícitamente una pequeña parte de las librerías que se incluyen en cada proyecto.


Ilustraremos la afirmación anterior con un suceso que hizo temblar npm.
En marzo de 2016, un desarrollador llamado Azer Koçulu, de California, recibió un correo de unos abogados de Kik Interactive.
Le pedían amablemente que cambiara el nombre de su librería llamada Kik, que había publicado en npm.
Resulta que los abogados decían que la marca \textit{Kik Messenger} les pertenecía a sus representados \cite{BoldiPaolo2019} por derechos 
de propiedad intelectual.
Koçulu no se quedó de brazos cruzados, se negó rotundamente a cambiar el nombre.
Los abogados, entonces, se pusieron en contacto con Isaac Schuleter, el director de npm, quien accedió a transferir el nombre.
Koçulu muy decepcionado con la decisión tomó medidas, y eliminó más de 250 paquetes del repositorio que habían sido desarrollados por él.


Entre los paquetes eliminados por Koçulu había uno llamado \textit{left-pad},
que era un simple script para justificar cadenas de texto. Pero… Muchos de los paquetes más populares de npm dependían directa
o indirectamente de \textit{left-pad}. Casi un millón de sitios web comenzaron a tener problemas para actualizar sus dependencias o
lanzar nuevas versiones, e incluso gigantes como Facebook o Netflix se vieron afectados. Fue un verdadero caos.


Finalmente, npm tuvo que intervenir y, aunque generó mucha polémica, decidieron restaurar el paquete \textit{left-pad}. Laurie Voss, 
el director de tecnología de npm, explicó que tomaron esta decisión sin precedentes debido a la gravedad y la amplia repercusión del 
problema. No lo hicieron a la ligera, la decisión se tomó pensando en la comunidad de usuarios de npm y en sus necesidades.


Después del incidente, se hizo evidente lo frágiles que son los sistemas de paquetes en los que depende una gran parte del desarrollo
de software en todo el mundo.
Surgieron muchas preguntas sobre el uso indiscriminado de librerías externas \cite{10.1145/3106237.3106267} y el modelo de gestión centralizada.
Es como darse cuenta de lo mucho que dependemos de ciertas cosas y preguntarnos si estamos siendo prudentes al hacerlo.
La problemática no se limita solo a la retirada voluntaria de un paquete en particular, como sucedió con \textit{left-pad}.
También puede ser causada por todo tipo de defectos en el software o ataques maliciosos que se propagan a través de la estructura de dependencias.
Según un informe llamado \textit{The state of open source security report}, las vulnerabilidades de seguridad en el software de código abierto
prácticamente se duplican cada dos años, y aproximadamente el 80\% de estas vulnerabilidades se introducen a través de dependencias indirectas.
Las conclusiones de este informe son preocupantes, e hicieron que el estudio de la seguridad y estabilidad de estos repositorios, que antes no había
recibido mucha atención se pusiese en el punto de mira de la comunidad \cite{10.5555/2820518.2820524} \cite{10.1145/3196398.3196401} \cite{BogartChristopherKastner2015}.


Es aquí donde entra la ciencia de redes\cite{barabasi2016network} a jugar un papel importante en el mundo del software.
Dado que las dependencias entre los proyectos de software, especialmente entre los paquetes de un repositorio,
se pueden representar como una red o un grafo dirigido y analizar desde una perspectiva estructural, la ciencia de
las redes se ha convertido en un enfoque reciente para comprender mejor la estructura y evolución \cite{7962360} de los
repositorios de paquetes de software. Es como mirar la forma en que todas estas piezas se conectan y se influyen mutuamente.
La ciencia de redes es una disciplina que se dedica a estudiar las redes complejas que podemos encontrar en muchos campos como la tecnología,
la biología y las ciencias sociales. Cuando decimos \textit{complejas} nos referimos al tamaño de las estructuras que se investigan y a la
falta de un patrón obvio de relaciones entre sus elementos. En los modelos de ciencia de redes, representamos estos elementos como nodos o vértices, mientras que las conexiones entre ellos se simbolizan con enlaces o aristas.
No es de sorprender que la ciencia de redes se base fundamentalmente en la teoría matemática de grafos, pero no es la única ciencia que
interviene en este análisis.
Es una materia interdisciplinaria que incorpora conocimientos de estadística, teorías de control e información, algoritmos,
minería de datos y muchas otras áreas de la informática.
Los principales logros de la ciencia de redes se centran en la construcción de modelos que explican la síntesis y evolución de las redes reales.
También se estudia la centralidad o importancia de los nodos, es decir, qué nodos son los más cruciales dentro de una red.
Además, se investiga la detección de agrupaciones significativas, como clústeres y comunidades, que revelan patrones interesantes dentro de una red.
Y por si fuera poco, se exploran fenómenos de difusión, es decir, cómo se propaga la información a través de las redes.


Alexandre Decan junto a otros investigadores \cite{10.1145/2993412.3003382}, realizaron un estudio en el que compararon el número de dependencias
directas y transitivas, así como el número de componentes débilmente conectados en los repositorios CRAN, PyPI y npm.
En otros estudios posteriores \cite{10.1109/SANER.2017.7884604}, sugieren que las estrategias actuales de versionado de paquetes
pueden causar problemas de falta de robustez en los repositorios. Esta conclusión fue demostrada experimentalmente en un análisis de
CRAN \cite{10.1109/SANER.2016.12}, apareciendo un patrón de comportamiento que a priori se mantiene común en los repositorios de software.
Por si eso no fuera suficiente, otro estudio \cite{10.1145/2901739.2901743} analiza la evolución del número de dependencias y la importancia
relativa de cada componente en npm. Utiliza PageRank como métrica para evaluar la centralidad de los paquetes y tienen en cuenta cómo
se utilizan en proyectos de GitHub.
Otro aspecto que se estudia en la ciencia de redes es la vulnerabilidad de la red. La vulnerabilidad se refiere a la incapacidad de la
red para funcionar correctamente cuando se eliminan algunos nodos o enlaces importantes \cite{posfai2016network}. Para medir la vulnerabilidad,
necesitamos conocer el tipo de red en particular. Por lo general, distinguimos entre casos en los que los problemas ocurren de manera aleatoria
o cuando son ataques intencionales \cite{Albert2000}. En el último caso, se supone que los atacantes utilizan información de la red para
planificar estrategias que provoquen el mayor daño posible o maximicen algún objetivo que generalmente va en contra de los intereses de los
actores de la red.
En cuanto a los repositorios de paquetes, un estudio \cite{10.1145/2901739.2901743} revela que la eliminación de un solo paquete puede
afectar al 30 \% de los paquetes y aplicaciones en los ecosistemas de JavaScript, Rust y Ruby.
Otro estudio \cite{10.1145/3196398.3196401} concluye que el número de vulnerabilidades encontradas en el código fuente de los paquetes
de npm ha estado aumentando constantemente desde 2012, propagándose a través de la red de dependencias.

OLIVIA \cite{daniel_2022_7358391}, desarrollada por el alumno Daniel Setó Rey como parte de su Trabajo de Fin de Grado en la Universidad de Burgos y tutorizada por los profesores Carlos López Nozal y Jose Ignacio Santos Martín en 2021, es una herramienta de código abierto que se centra en la identificación y análisis de defectos en bibliotecas de software desde la perspectiva de la teoría de grafos. Estos defectos pueden provocar errores funcionales, problemas de rendimiento e incluso problemas de seguridad. Para los desarrolladores, comprender completamente el riesgo es complicado, ya que solo importan explícitamente una pequeña parte de las dependencias utilizadas en sus proyectos.


OLIVIA utiliza un enfoque basado en la vulnerabilidad de la red de dependencias de los paquetes de software para medir la sensibilidad 
del repositorio a la introducción aleatoria de defectos. Su objetivo es contribuir a la comprensión de los mecanismos de propagación 
de defectos en el software y estudiar estrategias factibles de protección.

OLIVIA está en proceso de ser publicado a nivel académico\cite{Seto-Rey20231}
Después de su desarrollo como proyecto de fin de carrera, se están realizando los esfuerzos necesarios para 
compartir sus resultados y contribuciones con la comunidad científica.
Esta publicación permite que otros investigadores y profesionales del campo accedan a esta herramienta y se 
beneficien de su enfoque innovador en la identificación y análisis de vulnerabilidades en las bibliotecas de software. 
Además, sienta las bases para futuros avances
en la comprensión de los mecanismos de propagación de defectos y la implementación de estrategias efectivas de 
protección en el desarrollo de software.

Una vez que tenemos el modelo de análisis definido, lo que se necesitan son los datos a analizar mediante este.
La obtención de un conjunto de datos actualizado y el análisis a bajo nivel de los mismos, han aportado una 
actualización de los resultados relativamente obsoletos de \textit{Libraries.io}.

La recopilación de datos sobre las dependencias de los paquetes de software es un desafío complejo que puede 
resultar difícil de abordar.
Uno de los principales problemas radica en la falta de una única fuente confiable de información sobre estas dependencias.
En muchos casos, no existe un repositorio centralizado o una base de datos completa que contenga todos los detalles necesarios.
Debido a esta falta de una fuente única, recopilar datos sobre las dependencias de los paquetes de software a menudo 
requiere un esfuerzo manual y exhaustivo.
Los desarrolladores y analistas deben investigar y rastrear las dependencias de cada paquete individualmente, lo 
que puede llevar una cantidad considerable de tiempo y recursos.
Además, la información sobre las dependencias de los paquetes de software puede dispersarse en diferentes fuentes, 
como documentación oficial, repositorios de código, foros de desarrolladores y otras fuentes en línea.


Esta dispersión puede dificultar aún más la recopilación de datos y aumentar la posibilidad de omitir o malinterpretar 
información relevante.
El análisis de las redes de dependencias de paquetes de software es un proceso complejo debido a la naturaleza de estas 
redes, que pueden ser enormes y altamente interconectadas. Estas redes pueden contener miles o incluso millones de 
nodos y conexiones, lo que hace que el análisis manual sea prácticamente imposible.


Otro desafío asociado con la recopilación de datos es mantener la información actualizada. Las dependencias de los 
paquetes de software pueden cambiar con el tiempo debido a actualizaciones, nuevas versiones o cambios en los requisitos 
del sistema. Por lo tanto, es crucial realizar un seguimiento constante de los cambios y actualizar la información 
de las dependencias de manera regular para garantizar la precisión de los datos recopilados.


Para abordar estos desafíos, y como uno de los principales resultadoss de este TFG es ilustrar al 
lector de cómo poder enfrentarse a esta tarea, identificando las distintas vías de obtención de datos, y concluyendo 
con el desarrollo de una herramienta que facilita el proceso de obtención de los mismos desde los repositorios
oficiales de los gestores de paquetes que hemos elegido como caso de estudio.  En concreto nos referimos a la 
recopilación de datos de las dependencias en los paquetes de R (\textit{CRAN} y \textit{Bioconductor}), de Python \textit{PyPI} y de Node.js \textit{npm}.
